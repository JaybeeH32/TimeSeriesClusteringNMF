{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import rand_score\n",
    "import networkx as nx\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from preprocess import load_ts_dataset, distance_matrix, epsilon_graph_hard, epsilon_graph_mean\n",
    "from clustering_algos import line_clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of datasets\n",
    "# ['Adiac', 'ArrowHead', 'Beef', 'BeetleFly', 'BirdChicken', 'Car', 'CBF', 'ChlorineConcentration', 'CinCECGTorso', 'Coffee', 'Computers', 'CricketX', 'CricketY', 'CricketZ', 'DiatomSizeReduction', 'DistalPhalanxOutlineCorrect', 'DistalPhalanxOutlineAgeGroup', 'DistalPhalanxTW', 'Earthquakes', 'ECG200', 'ECG5000', 'ECGFiveDays', 'ElectricDevices', 'FaceAll', 'FaceFour', 'FacesUCR', 'FiftyWords', 'Fish', 'FordA', 'FordB', 'GunPoint', 'Ham', 'HandOutlines', 'Haptics', 'Herring', 'InlineSkate', 'InsectWingbeatSound', 'ItalyPowerDemand', 'LargeKitchenAppliances', 'Lightning2', 'Lightning7', 'Mallat', 'Meat', 'MedicalImages', 'MiddlePhalanxOutlineCorrect', 'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxTW', 'MoteStrain', 'NonInvasiveFatalECGThorax1\n",
    "# select the dataset you want to use \n",
    "\n",
    "data_str = 'Coffee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### if data_str = ptb\n",
    "\n",
    "MAX_LEN = 100\n",
    "data_normal = pd.read_csv('ptbdb_normal.csv').iloc[:MAX_LEN].to_numpy()\n",
    "data_abnormal = pd.read_csv('ptbdb_abnormal.csv').iloc[:MAX_LEN].to_numpy()\n",
    "data = np.concatenate([data_normal, data_abnormal], axis=0)\n",
    "\n",
    "true_labels = np.concatenate([np.zeros(MAX_LEN), np.ones(MAX_LEN)])\n",
    "\n",
    "ts_length = len(data[0])\n",
    "# suffle dataset\n",
    "shuffl = np.concatenate([data, np.expand_dims(true_labels, axis=1)], axis=1)\n",
    "np.random.shuffle(shuffl)\n",
    "\n",
    "data, true_labels = shuffl[:, :ts_length - 1], shuffl[:, -1].astype(np.int64)\n",
    "DIMENSION = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### else \n",
    "\n",
    "dataset = load_ts_dataset(data_str)\n",
    "data, true_labels = dataset[0], dataset[1]\n",
    "dist = distance_matrix(data)\n",
    "dist = dist / np.max(dist)\n",
    "A = epsilon_graph_hard(dist, epsilon=0.478297)\n",
    "# A = epsilon_graph_mean(dist)\n",
    "G = nx.from_numpy_array(A)\n",
    "DIMENSION = np.max(true_labels) + 1*(0 in true_labels)\n",
    "DIMENSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, to apply the function, you need to specific the values of epsilon for which you used LINE \n",
    "\n",
    "for ep in [0.1 * k for k in range(2,6)]: #here we tested values for epsilon in 0.2 to 0.6\n",
    "    predicted_clusters = line_clustering(data_str, eps = int(100*ep)/100, d = DIMENSION)\n",
    "    print(rand_score(true_labels, predicted_clusters), ep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
